import streamlit as st
import torch
from torchvision.models import resnet18
from torchvision import transforms
from PIL import Image
import torch.nn.functional as F
import os
import urllib.request

st.set_page_config(
    page_title="ì´ê²Œë­˜ê¹Œ",
    page_icon="ğŸ§ ",
    layout="centered",
    initial_sidebar_state="collapsed"
)

MODEL_PATH = "model/classifier.pt"
CLASSES_PATH = "model/classes.txt"
HF_URL = "https://huggingface.co/diplemong/brainrot-classifier/resolve/main/classifier.pt"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ íŒŒì¼ ìë™ ë‹¤ìš´ë¡œë“œ
if not os.path.exists(MODEL_PATH):
    os.makedirs("model", exist_ok=True)
    with st.spinner("ëª¨ë¸ì´ ì—†ì–´ì„œ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤..."):
        urllib.request.urlretrieve(HF_URL, MODEL_PATH)
    st.success("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

# í´ë˜ìŠ¤ ì´ë¦„ ë¡œë“œ
with open(CLASSES_PATH, "r") as f:
    class_names = [line.strip() for line in f]

# ëª¨ë¸ êµ¬ì¡° ì„¤ì • ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
model = resnet18(weights=None)
model.fc = torch.nn.Linear(model.fc.in_features, len(class_names))
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model.to(DEVICE)
model.eval()

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

def predict_image(image):
    img = transform(image).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        output = model(img)
        probs = F.softmax(output, dim=1)[0]
    return probs.cpu()

# UI ì‹œì‘
st.markdown("""
    <div style='text-align:center'>
        <h1 style='color:#FF4B4B;'>ë‚˜ì™€ ë‹®ì€ ë¸Œë ˆì¸ë¡¯ ìºë¦­í„°ëŠ”?</h1>
        <p style='color:gray;'>AIê°€ ë‹¹ì‹ ì˜ ì–¼êµ´ì„ ë¶„ì„í•´ ë‹®ì€ ë¸Œë ˆì¸ë¡¯ ìºë¦­í„°ë¥¼ ì°¾ì•„ë‚´ ì¤ë‹ˆë‹¤</p>
    </div>
""", unsafe_allow_html=True)

st.markdown("### ì´ë¯¸ì§€ ì—…ë¡œë“œ")
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”!", type=["jpg", "jpeg", "png"])

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

    probs = predict_image(image)
    top_idx = torch.argmax(probs).item()

    class_name_map = {
        "brrbrr": "ë¸Œë¥´ë¥´ ë¸Œë¥´ë¥´ íŒŒíƒ€í•Œ",
        "TralaleroTralala": "íŠ¸ë„ë„ë ë¡œ íŠ¸ë„ë„ë¼",
        "lirililarila": "ë¦¬ë¦´ë¦¬ ë¼ë¦´ë¼",
        "tung9sahur": "í‰ í‰ í‰ í‰ í‰ í‰ í‰ í‰ í‰ ì‚¬í›„ë¥´",
        "ChimpanziniBananini": "ì¹¨íŒì¹˜ë‹ˆ ë°”ë‚˜ë‹ˆë‹ˆ",
        "BombardiroCrocodilo": "ë´„ë°”ë¥´ë”œë¡œ í¬ë¡œì½”í‹¸ë¡œ"
    }

    raw_top_class = class_names[top_idx]
    top_class = class_name_map.get(raw_top_class, raw_top_class)
    top_prob = probs[top_idx].item()

    st.markdown("---")
    st.markdown(f"""
        <div style='padding:1em; border-radius:12px; background:#f9f9f9; text-align:center;'>
            <h2 style='color:#2ecc71;'> ë‹¹ì‹ ì€ <span style='color:#FF8C00;'>{top_prob*100:.2f}%</span> ë¹„ìœ¨ë¡œ</h2>
            <h1 style='color:#e74c3c'>{top_class}</h1>
        </div>
    """, unsafe_allow_html=True)

    sorted_probs = sorted(enumerate(probs), key=lambda x: x[1], reverse=True)
    labels = [class_names[i] for i, _ in sorted_probs]
    values = [float(p) for _, p in sorted_probs]

    for name, val in zip(labels, values):
        st.progress(val, text=f"{name} ({val*100:.2f}%)")
